# Research

My research career in computational science spans a wide variety of computational projects in the physical sciences.

Over the years, each of these research topics succeeded only because I have been so fortunate to work with so many amazing collaborators and scientific mentors.

For an overview of my research partners, see my Acknowledgements page. Read on for a brief selection of research highlights over my career.

## Nuclear Reactions In Astrophysics

### Mathematically Modeling Nuclear Reactions

Nuclear physics powers a vast array of high energy astrophysics events, from
fusion in stars to supernovae and neutron star dynamics. Nuclear reactions
between atomic nuclei within stellar environments generate energy for starlight
and power hydrodynamics and observable radiation.

We model observed energy generation from nuclei by writing rate equations that
couple high temperature nuclei. We assemble theoretial cross-sections and
available experimental data from particle accelerators to calculate the nuclear
reaction rates at various temperatures.

I worked with Mike Zingale to create pynucastro, an open-source Python package
for interfacing iwth nuclear databases. With pynucastro, researchers and
students alike can easily:

- plot nuclear reaction rates
- assemble nuclear reaction networks specific to the astrophysics conditions they wish to model
- solve the nuclear reaction equations
- output clear C++ or python code to calcuate nuclear reaction models in other astrophysics simulation codes

```
cite: pynucastro JOSS paper
cite: pynucastro methods paper
```

### Computationally Solving Nuclear Reactions

Nuclear reaction equations actually look mathematically similar to rate
equations for chemistry or biological populations. We solve any equations of
this time using a variety of time integration techniques for coupled, first
order ordinary differential equations.

Nuclear reactions in particular are especially sensitive to temperature, after
all, that's why stars can explode in thermonuclear runaway! This extreme
temperature sensitivity makes numbers in our equations tend to "blow up"
quickly too, so we have to take small, careful arithmetic steps to solve these
equations.

In mathematical terms, we have to use implicit time integration with careful
error control. All such techniques achieve accuracy by implementing more
careful calculations. Careful calculations and good error control require
additional arithmetic steps, so we need more computing resources to make
accurate predictions. While the accuracy versus efficiency tradeoff is
especially prominent in nuclear astrophysics, virtually all other fields in
computational science struggle with this exact issue.

(If you've ever wondered why meteorologists can get weather predictions wrong,
 well, it's likely their predictive calculations traded too much accuracy for
 efficiency!)

Note: If we carelessly write simulation code, even the fastest supercomputers
will simply give us wrong answers fast!

To take advantage of modern heterogeneous supercomputers with lots of GPUs, I
ported the VODE solver for implicit time integration from Fortran 77 to CUDA
Fortran. But I realized there could be no room for mistakes, so I followed the
old adage - "trust but verify."

In my case, I spent every effort to accurately port a highly complex code.
Anyone who has ever had to trace the combinatoric pathways of nested `go to`
statements will sympathize! But I didn't fully trust that I had made no
mistakes or that the GPUs would yield correct answers. So I carefully verified
the code, requiring that it give me exactly the same results as before the port
when comparing CPU calculations. When running my new code on the GPUs, I
allowed its results to differ from the CPU results only at the level of
numerical roundoff error.

Our collaboration described this port and the science our combined reaction and
hydrodynamics code enabled in our paper for Supercomputing 20.

```
cite: SC20 paper
```

Later, we ported my CUDA Fortan integrator to inlined CUDA C++.

We now use generic macros from the AMReX framework allowing us to compile the
same C++ integrator for CPUs, NVIDIA GPUs, or AMD GPUs.

We published our work and our open-source scientific computing codes in a
series of papers.

```
cite: all relevant code and conference papers, including JOSS
```

While we directly communicated our methods and open code to the wider
astrophysics community, our solutions are broadly applicable to related
challenges all across computational science.

## Neutron Star Astrophysics

### X-ray Bursting Neutron Stars

!Note: Solving nuclear reactions on GPUs enables accelerated nuclear astrophysics simulations!

My GPU work enabled our nuclear astrophysics collaboration to simulate detailed
two and three-dimensional nuclear flames on neutron star surfaces!

Neutron stars in binary star systems can under certain astrophysical conditions
accrete material from their companion star. In these cases, the neutron star's
atmosphere can undergo periodic thermonuclear runaway burning visible from
Earth as a bright burst of X-rays.

By carefully modeling the X-ray burst physics, we hope to correlate observed
X-ray bursts with properties of the unseen, super-dense neutron star core
hiding below its atmosphere.

```
cite: XRB I Paper
cite: XRB II Paper
cite: relevant conference papers
```

### Particle Acceleration in Neutron Star Environments

At LBL, I also collaborated with scientists who worked on electromagnetic
modeling for particle accelerator physics. Together, we started a project to
model relativistic particle acceleration from magnetic reconnection in rapidly
rotating neutron star magnetospheres.

We worked with a talented intern, Eloise Yang, who set up these simulations in
the WarpX electromagnetic particle-in-cell (PIC) code. After Eloise left LBL,
postdoc Hannah Klion picked up the project. Our combined efforts succeeded,
and our project's first paper explored new advances in electromagnetic PIC
solver methods and their utility for simulating charge acceleration from
relativistic magnetic reconnection.

```
cite: Klion+ MR paper
```

This research sets the foundation for applying our numerical
methods to simulate high-energy particle emission from not only magnetic
reconnection but also cosmic ray acceleration in other astrophysical
environments.

## Thermonuclear Supernovae

### Thermonuclear SN from hybrid white dwarf Stars

I started out my astrophysics career simulating deflagrations and detonations
in "hybrid" white dwarf stars. The typical white dwarf (WD) star is within
about forty percent give or take from our own sun's mass, made up of the
elements carbon and oxygen, all compacted down to the size of our Earth. Hybrid
white dwarfs are so called because they are hypothetically composed of carbon,
oxygen, and neon. I wanted to discover whether runaway thermonuclear
fusion in such hybrid white dwarf stars could possibly generate Type Ia
supernovae.

Type Ia supernovae (SNIa) are extremely bright explosions of white dwarf stars.
Yet SNIa are very rare, only occurring about twice a century in a typical
galaxy. We can observe SNIa from distant galaxies, however, because in the
aftermath of runaway thermonuclear fusion, the explosion of a single SNIa is
briefly brighter than its entire galaxy. Astrophysicists used SNIa to measure
distances to faraway galaxies and their velocities compared to our Milky Way
galaxy. They found that the Universe was not only expanding but also
mysteriously accelerating outwards over time, as if powered by an unknown form
of energy they labeled "Dark Energy."

But what if unexpected types of stars could undergo thermonuclear runaway and
appear to be SNIa but differ in subtle ways to corrupt our measurements of the
Universe's acceleration?

Perhaps investigating this possibility will help us figure out Dark Energy.

This thinking motivated my first astrophysics research paper where I used
computer simulations to estimate whether "hybrid" carbon-oxygen-neon white
dwarf stars could undergo thermonuclear runaway like SNIa from pure
carbon-oxygen white dwarf stars. In other words, could "hybrid" white dwarf
stars produce impostor SNIa events?

I found that while the explosion dynamics from hybrid white dwarf stars were
similar to explosions from typical white dwarf stars, hybrids were unlikely to
generate impostor SNIa.

This might be reassuring from a cosmological perspective, but why don't hybrid
white dwarf stars explode like ordinary white dwarf stars?

I found the key explanation for this finding lies in the evolutionary history
for hybrid white dwarfs. The hybrid white dwarf hypothesis requires that
earlier in the lifecycle of these stars, they partially burned their carbon to
produce neon. By trading carbon for neon, hybrid white dwarfs have less nuclear
potential energy available to power the final, explosive thermonuclear runaway.
Lower nuclear potential energy at the start of thermonuclear runaway than an
equal mass carbon and oxygen white dwarf means thermonuclear runaways from
hybrids will on average generate lower kinetic and radiative energy. In other
words, explosions from hybrid white dwarfs will be significantly dimmer than
explosions from typical white dwarfs.

```
cite: Willcox+ 2016 paper
```

### Thermonuclear Supernovae From Convectively Mixed Hybrid White Dwarf Stars

I moved on to other astrophysics topics, but I still remained involved as my
collaborators worked to advance my hybrid white dwarf research. We wished to
examine whether convective mixing during earlier stages of hybrid carbon,
oxygen, neon white dwarf stellar history would change my findings. We
found that mixed carbon, oxygen, neon hybrid white dwarfs compared to
carbon and oxygen white dwarfs remained likely dimmer and less
energetic when undergoing thermonuclear runaway.

Our new result was largely consistent with my earlier findings, but it was
still important to check thoroughly. Nuances just like this can sometimes have
surprising effects.

```
cite: Augustine+ mixed c/o/ne hybrid paper
```

### Deflagrations from Convectively Mixed Hybrid White Dwarf Stars

More recently, a newer graduate student followed up on our earlier hybrid white
dwarf research by investigating the potential of hybrid white dwarf stars to
produce dimmer Type Iax supernovae.

This Iax hypothesis was motivated by recognizing that all our earlier
thermonuclear runaway simulations modeled our best understanding for producing
bright Type Ia supernovae from single white dwarf stars. To simulate SNIa
events from single white dwarf stars, we used a deflagration-to-detonation
transition model to completely burn carbon fuel all the way to nuclear
statistical equilibrium at the iron peak.

SNIa are known to produce elements as heavy as iron but not much heavier, that
is to say, SNIa do not produce elements with much larger atomic mass on the
periodic table of elements. This pattern is typical for thermonuclear fusion
and it is a natural consequence of the fact that atomic elements around the
mass of iron are the most stable of all elements we have so far discovered.

Type Iax supernovae are different, however, being dimmer than SNIa. If they
come from white dwarf stars, then it is possible they simply did not completely
burn all their initial carbon fuel to produce heavy elements. This would result
in lower energy generation available to power explosive ejecta and observed
radiation. We wanted to find out whether the hypothesized carbon, oxygen, neon
hybrid white dwarfs could explain Type Iax observations.

This time, instead of simulating explosions with a deflagration-to-detonation
transition model during thermonuclear runaway, graduate student Catherine
Feldman simulated pure deflagration in hybrid white dwarfs to allow for
significant incomplete nucleosynthesis.

As before, I assisted wherever able with explaining my original method and
providing feedback to the research.

Catherine found [...] and published this work as follows:

```
cite: Dimming the Lights, Feldman+
```

## Neutrino Quantum Kinetics

In certain high energy astrophysics contexts, like core-collapse supernovae and
neutron star mergers, neutrinos are radiated at such high densities they are
capable of exhibiting collective behavior as a many-body quantum system. At the
same time, neutrinos travel at nearly the speed of light and must be modeled
using the techniques of radiation transport.

It so happens that neutron star mergers, and to a lesser extent, core collapse
supernovae, are understood by astrophysicists to produce the majority of all
elements heavier than iron on the periodic table, such as gold. Since neutrinos
interact with neutrons and protons, neutrinos influence the likelihood of
various nucleosynthesis pathways for creating all these heavy elements.

But how can we make accurate estimations of which astrophysics events produced
various quantities of elements? Well, we observe radiation spectra from these
events, then we match these observed spectra with detailed computational models
of the explosion and the radiation it produces to determine the starting
conditions for the explosion.

But computing the influence of neutrinos is fairly difficult, we have to solve
a radiation transport problem in six dimensions (three space plus two angular
dimensions plus time). Then as if radiation transport weren't difficult enough,
we need to solve a many-body quantum mechanics problem to evolve the neutrino
flavor states.

Why is the quantum mechanics important?

Because under certain conditions, theorists have found neutrinos can evolve
fast flavor instabilities (FFI). Under FFI conditions, the overall neutrino
flavor state very rapidly destabilizes before approaching a completely
different equilibrium state over longer timescales.

The problem is that these FFI events can occur in volumes of space that would
fit into the palm of one's hand, over timescales measured in just a few
nanoseconds. This is far faster than explosion simulations can possibly
capture, so we need to write a specialized simulation code just for neutrino
quantum kinetics. We can then predict what conditions could lead to FFI and the
long term outcomes to provide effective models for larger, more complete
simulations of the entire explosion event.

I worked with Sherwood Richers to create a new simulation code based on the
particle-in-cell technique to solve neutrino quantum kinetics in the mean field
approximation. We represent the neutrino radiation field using Lagrangian
particles traveling atop an underlying spatial mesh that contains the mean
field quantum many-body state as well as the nuclear matter background.

```
cite: Emu Code Paper
cite: Emu 3D FFI Paper
```

## Code Generation To Solve PDEs

While at Berkeley Lab, I worked with other computational scientists to create
automated code generation methods for solving PDE systems using either Eulerian
or Lagrangian techniques.

Our codes are open-source, and our methods are generally useful for a wide
variety of scientific contexts where PDEs exist or could be devised but would
be challenging to solve. We can translate symbolic PDEs into high performance
code very simply and create a simulation package ready to run on modern
GPU-accelerated supercomputers.

If you would like to collaborate on such research, you are always welcome to
reach out.

### Creating STvAR To Generate Adaptive-Mesh Eulerian PDE Solvers

```
cite: STvAR code paper
```

### Using STvAR To Narrow Hypothetical Limits On Axion Dark Matter

```
cite: Axion simulation paper
```

### Creating A Code Generation Lagrangian Transport Framework

The framework I created for the Emu code, where we solved the equations of
neutrino quantum kinetics, is actually much more general. All the neutrino
physics is generated for the Lagrangian particle computational kernels using
Sympy to translate the quantum flavor equations into inlined C++ functions.

Emu's main codebase is actually a general Lagrangian transport method using
Runge-Kutta to update particle positions and their internal state together. The
right-hand side for the differential equations we solve happens to use an
underlying mesh and particle-in-cell operations to evaluate mean-field
quantities. However, in principle we could easily use nearest-neighbor particle
operations for a purely Lagrangian approach. The AMReX framework supports both
particle-mesh and particle-particle computational kernels for production codes.

I'm interested in using this general Lagrangian PDE solver method for other PDE
systems where Eulerian methods introduce too much numerical diffision to the
transport solver. Our method would be especially useful if the Lagrangian
transport elements possess active, time-varying properties. This would be an
excellent technique for transport simulations of active fluids, for example.

```
cite: Emu Code Paper
cite: Emu 3D FFI Paper
```

## Machine Learning For Surrogate Models In Astrophysics

Nuclear reactions are computationally intensive!

After working to accelerate our reaction solvers on GPUs, I saw the great
utility of machine learning for assisting PDE solvers and started a project to
address an important question the astrophysics community had not yet
researched.

What if we could replace expensive, time-consuming reaction network solvers
with good approximate surrogate models using machine learning?

If successful, ML surrogate techniques could drastically speed up the most
time-intensive reaction physics module in nearly all explosive astrophysics
simulations.

Why?

Well, in high-energy nuclear astrophysics (think supernovae and neutron star
mergers), turbulence, radiation, and nuclear reactions drive the dynamics. Yet,
especially in the reaction physics case, these equations mathematically
generate stiff nonlinearities where we must focus computational intensity to
solve with acceptable accuracy. Approximate methods can be wildly wrong!

Physics-informed neural networks (PINNs) are promising but the equations we
must solve for reaction physics are not only nonlinear but extremely stiff. In
mathematical terms, when we construct a linear approximation to the full
equations, the ratio of Jacobian elements can be greater than twenty orders of
magnitude for explosive burning simulations. This makes the gradient error
functions in PINNs quite difficult to use for training surrogate models over a
large enough dynamic range to capture a complete burning model.

We thus started our research with a simpler forward neural network and found we
needed a recurrent neural network for gradient descent to train the network
effectively. We studied simple laminar flame models to start out instead of
going straight to turbulent flame modeling.

Our first paper thus demonstrated a successful proof-of-concept method for
nuclear reaction surrogate modeling.

```
cite: ML Flame Paper
```

I'm eager to extend our initial work to explosive astrophysics by expanding the
training dataset to a more comprehensive flame model. In addition, there are
many follow-up questions for investigating alternate neural network structures
and training techniques to better incorporate reaction physics constraints.

## Computational Science Philosophy

I am equally a computational scientist as I am a physicist. In fact, I consider
all these tightly interrelated. I analyze research topics from a physics
perspective. Then I use the tools of computation and applied mathematics to
carry out science by testing and falsifying hypotheses.

### My Approach To Computational Science

My approach is to achieve reproducible results by thorough code documentation,
strict version control, and ongoing testing.

Validation is ongoing, not just at the end of a project or done once and then
forgotten.

Development should keep in mind specific tests the numerical code should pass.
Sometimes this means unit tests, sometimes this means regression tests.

Run tests on an ongoing basis using Continuous Integration through, e.g. GitHub
Actions or an equivalent.

Catch regression or unit test errors at pull request review time, if not
earlier, before breaking changes have a chance to make it into the main code.
This simple approach is enormously useful when a bug appears in my simulations
and I find myself backtracking through the code history to pinpoint where it
came from!

Always have someone review your code, even if you are just working with one
other person.

```
cite: links to our regression docs, GitHub Actions CI, and online regtest results pages.
```

### What's Next For My Computational Research?

Quite a lot! Here are some research directions I am looking forward to pursuing
next:

- Applying forward simulation techniques I've developed to novel scientific
  contexts

- Efficient forward simulations for solving inverse problems

- Incorporating data science of observations to better guide numerical
  simulations to the right initial hypotheses

- Combining Machine Learning surrogate modeling with multiscale simulation
  frameworks with reliable error control

- Adaptive subgrid methods that more efficiently use computational resources by
  adapting our accuracy to each term in the PDE system we model

